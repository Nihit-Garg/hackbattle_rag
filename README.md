# hackbattle_rag



llm- qwen 2.5 3b model from ollama locally downloaded 
embeddings model- nomic-embed-text from Ollama using locally 

The hyde pipeline is working and vague prompts like od?, venue?, etc are working.
The output sometimes show the phrases like based on context, that is because i am storing the chat history which can be removed and then no such problem would occur.
